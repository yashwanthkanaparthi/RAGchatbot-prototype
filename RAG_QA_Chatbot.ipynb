{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvZl16Wa1eeG",
        "outputId": "b4a07504-e54e-45ed-9af1-b032579cb383"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/9.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/9.9 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m7.0/9.9 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m113.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.4/131.4 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m129.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install streamlit pyngrok python-dotenv groq pymupdf sentence-transformers faiss-cpu pillow pytesseract\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgXjEKWi1tOD",
        "outputId": "05c92ea1-372e-4a08-b816-67d4b481eb85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ finalapp.py loaded\n",
            "\n",
            "Preview (first 2000 chars):\n",
            "\n",
            "import os import re import io import json import uuid import hashlib from pathlib import Path from typing import List, Dict, Any, Optional import numpy as np import streamlit as st from dotenv import load_dotenv from textwrap import dedent # ---- PDF text extraction ---- import fitz # PyMuPDF # ---- Optional OCR (for scanned PDFs) ---- try: import pytesseract from PIL import Image _OCR_AVAILABLE = True except Exception: _OCR_AVAILABLE = False # ---- Embedding + Reranker (HuggingFace) ---- from sentence_transformers import SentenceTransformer, CrossEncoder # ---- FAISS (vector index) ---- try: import faiss # faiss-cpu _FAISS_AVAILABLE = True except Exception: _FAISS_AVAILABLE = False # ---- Groq LLM ---- from groq import Groq # ========================================= # Config / Globals # ========================================= load_dotenv() # Hardcode models (as we agreed earlier) EMBED_MODEL_ID = \"abhinand/MedEmbed-large-v0.1\" RERANK_MODEL_ID = \"BAAI/bge-reranker-v2-m3\" GROQ_CHAT_MODEL = os.getenv(\"GROQ_CHAT_MODEL\", \"llama-3.3-70b-versatile\") GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\") # ⚠️ System prompt restored to the plain, earlier style (same spirit as your original finalapp2.py) GENERAL_SYSTEM_INSTRUCTIONS = \"\"\" You are a precise document QA assistant. Answer ONLY using the supplied documents. - If the user asks to extract specific sections (e.g., Abstract, Methods, Results), find and return those spans verbatim where possible. - For tables, reconstruct table content present in text as Markdown tables; if table text is not present, say so. - For figures/images, report captions or references if present in text; otherwise explain they are not available as text. - If the answer is not present in the provided documents, say you cannot find it. Keep answers concise and faithful to the source text. \"\"\" DEFAULT_RETRIEVE_TOP_K = 12 DEFAULT_RERANK_TOP_K = 5 CACHE_ROOT = Path(\".rag_cache\") # ========================================= # Streamlit Page # ...[truncated]...\n"
          ]
        }
      ],
      "source": [
        "import os, textwrap, sys\n",
        "\n",
        "path = \"demoapp.py\"  # make sure you uploaded this to the Colab working dir\n",
        "assert os.path.exists(path), \"finalapp.py not found. Upload it first (left sidebar → Files → Upload).\"\n",
        "\n",
        "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "    code = f.read()\n",
        "\n",
        "print(\"✓ demoapp.py loaded\\n\")\n",
        "print(\"Preview (first 2000 chars):\\n\")\n",
        "print(textwrap.shorten(code, width=2000, placeholder=\" ...[truncated]...\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iO7TdD_O12fN",
        "outputId": "1b9846f1-c88c-476d-b2cb-d542fe93f0e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 Public URL: https://d8b19deb0d03.ngrok-free.app\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "NGROK_AUTH_TOKEN = \"API_KEY\"  # <-- put your token here (https://dashboard.ngrok.com/get-started/your-authtoken)\n",
        "ngrok.kill()\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# Streamlit default port\n",
        "PORT = 8501\n",
        "public_tunnel = ngrok.connect(PORT, \"http\")\n",
        "print(\"🚀 Public URL:\", public_tunnel.public_url)\n",
        "\n",
        "# Optional: set your API key for the app (or load via .env inside your app)\n",
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = \"API_KEY\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TozO3WHI2FWy",
        "outputId": "4f3a7932-36c9-4ec8-b331-db54831cad84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  URL: \u001b[0m\u001b[1mhttp://0.0.0.0:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!streamlit run demoapp.py --server.port 8501 --server.address 0.0.0.0\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
