{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QvZl16Wa1eeG"
      },
      "outputs": [],
      "source": [
        "!pip -q install streamlit pyngrok python-dotenv groq pymupdf sentence-transformers faiss-cpu pillow pytesseract\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgXjEKWi1tOD",
        "outputId": "87ae39b4-dc8b-4acf-a49d-1c1115ec16dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ finalapp.py loaded\n",
            "\n",
            "Preview (first 2000 chars):\n",
            "\n",
            "# app_single.py # One-file Streamlit Document QA app (UI + VectorStore + Chatbot) # - Streamlit UI with \"+\" uploader and filename pill # - VectorStore: PyMuPDF -> text, semantic chunking, sentence-transformer embeddings, optional FAISS, optional OCR, BGE reranker # - Chatbot: Groq chat completion (streamed), answers strictly from retrieved docs # # Requirements (typical): # streamlit # python-dotenv # groq # pymupdf # sentence-transformers # faiss-cpu (optional; falls back to numpy search if missing) # pillow, pytesseract (optional; for OCR on scanned PDFs) # # Env (.env or system): # GROQ_API_KEY=... # GROQ_CHAT_MODEL=llama-3.3-70b-versatile (default) # EMBED_MODEL=pritamdeka/S-PubMedBert-MS-MARCO # RERANK_MODEL=BAAI/bge-reranker-v2-m3 # # Run: # streamlit run app_single.py import os import re import uuid from typing import List, Dict, Any, Optional import numpy as np import streamlit as st from dotenv import load_dotenv from textwrap import dedent # ---- PDF text extraction ---- import fitz # PyMuPDF # ---- Optional OCR (for scanned PDFs) ---- try: import pytesseract from PIL import Image import io _OCR_AVAILABLE = True except Exception: _OCR_AVAILABLE = False # ---- Embedding + Reranker (HuggingFace) ---- from sentence_transformers import SentenceTransformer, CrossEncoder # ---- FAISS (vector index) ---- try: import faiss # faiss-cpu _FAISS_AVAILABLE = True except Exception: _FAISS_AVAILABLE = False # ---- Groq LLM ---- from groq import Groq # ============================ # VectorStore (merged) # ============================ class VectorStore: \"\"\" Open-source RAG backend: â€¢ Semantic chunking (sentence-level cosine dips) â€¢ PubMedBERT embeddings (configurable via EMBED_MODEL env) â€¢ FAISS index (cosine via normalized vectors) â€¢ BGE cross-encoder reranker (configurable via RERANK_MODEL env) \"\"\" def __init__(self, pdf_path: str): self.pdf_path = pdf_path # Configurable (via env) model IDs self.embed_model_id = \"abhinand/MedEmbed-large-v0.1\" ...[truncated]...\n"
          ]
        }
      ],
      "source": [
        "import os, textwrap, sys\n",
        "\n",
        "path = \"finalapp2.py\"  # make sure you uploaded this to the Colab working dir\n",
        "assert os.path.exists(path), \"finalapp.py not found. Upload it first (left sidebar â†’ Files â†’ Upload).\"\n",
        "\n",
        "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "    code = f.read()\n",
        "\n",
        "print(\"âœ“ finalapp.py loaded\\n\")\n",
        "print(\"Preview (first 2000 chars):\\n\")\n",
        "print(textwrap.shorten(code, width=2000, placeholder=\" ...[truncated]...\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iO7TdD_O12fN",
        "outputId": "588aa197-e4f7-4712-b70c-938bf3e4e80f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ Public URL: https://68a2796f6966.ngrok-free.app\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "NGROK_AUTH_TOKEN = \"API_KEY\"  # <-- put your token here (https://dashboard.ngrok.com/get-started/your-authtoken)\n",
        "ngrok.kill()\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# Streamlit default port\n",
        "PORT = 8501\n",
        "public_tunnel = ngrok.connect(PORT, \"http\")\n",
        "print(\"ðŸš€ Public URL:\", public_tunnel.public_url)\n",
        "\n",
        "# Optional: set your API key for the app (or load via .env inside your app)\n",
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = \"GROQ_API_KEY\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TozO3WHI2FWy",
        "outputId": "c1b10aa2-b340-4b54-d704-fc83fedd35fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  URL: \u001b[0m\u001b[1mhttp://0.0.0.0:8501\u001b[0m\n",
            "\u001b[0m\n",
            "2025-08-20 12:15:15.761595: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1755692115.785115    2050 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1755692115.792208    2050 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1755692115.809951    2050 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755692115.809992    2050 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755692115.809996    2050 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755692115.810000    2050 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-08-20 12:15:15.815609: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "Exception ignored in atexit callback: <function dump_compile_times at 0x784272bad620>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/utils.py\", line 811, in dump_compile_times\n",
            "    log.info(compile_times(repr=\"str\", aggregate=True))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/utils.py\", line 797, in compile_times\n",
            "    out += tabulate(rows, headers=(\"Function\", \"Runtimes (s)\"))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/_dynamo/utils.py\", line 226, in tabulate\n",
            "    import tabulate\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tabulate/__init__.py\", line 52, in <module>\n",
            "    Line = namedtuple(\"Line\", [\"begin\", \"hline\", \"sep\", \"end\"])\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/collections/__init__.py\", line 441, in namedtuple\n",
            "    __new__ = eval(code, namespace)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<string>\", line 0, in <module>\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/streamlit/web/bootstrap.py\", line 43, in signal_handler\n",
            "    server.stop()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/streamlit/web/server/server.py\", line 509, in stop\n",
            "    self._runtime.stop()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/streamlit/runtime/runtime.py\", line 329, in stop\n",
            "    async_objs.eventloop.call_soon_threadsafe(stop_on_eventloop)\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 844, in call_soon_threadsafe\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 545, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n"
          ]
        }
      ],
      "source": [
        "!streamlit run finalapp2.py --server.port 8501 --server.address 0.0.0.0\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
